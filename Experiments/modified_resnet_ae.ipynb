{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":126766,"databundleVersionId":15067517,"sourceType":"competition"}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\n# --- 1. AUTO-FIND THE PATH ---\nprint(\"ðŸ•µï¸â€â™‚ï¸ Searching for 'training_videos'...\")\n\nfound_train_path = \"\"\n# Walk through the entire input directory to find the folder\nfor root, dirs, files in os.walk('/kaggle/input'):\n    if \"training_videos\" in dirs:\n        found_train_path = os.path.join(root, 'training_videos')\n        print(f\"âœ… FOUND IT! The correct path is:\\n{found_train_path}\")\n        break\n\nif found_train_path == \"\":\n    print(\"âŒ ERROR: Could not find the folder. Check if the dataset is added!\")\nelse:\n    # --- 2. LIST FOLDERS ---\n    video_folders = sorted(os.listdir(found_train_path))\n    print(f\"\\nðŸ“‚ Found {len(video_folders)} video folders (e.g., {video_folders[:3]}...)\")\n\n    # --- 3. SHOW AN IMAGE ---\n    # Go inside the first video folder\n    first_video_path = os.path.join(found_train_path, video_folders[0])\n    frame_files = sorted(os.listdir(first_video_path))\n    \n    # Pick the first image\n    img_path = os.path.join(first_video_path, frame_files[0])\n    \n    # Display\n    img = mpimg.imread(img_path)\n    plt.figure(figsize=(5,5))\n    plt.imshow(img)\n    plt.title(f\"Success! Viewing: {video_folders[0]}/{frame_files[0]}\")\n    plt.axis('off')\n    plt.show()\n    \n    print(f\"Image Shape: {img.shape}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-03T08:06:47.400615Z","iopub.execute_input":"2026-01-03T08:06:47.401362Z","iopub.status.idle":"2026-01-03T08:06:47.512270Z","shell.execute_reply.started":"2026-01-03T08:06:47.401331Z","shell.execute_reply":"2026-01-03T08:06:47.511646Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.utils import image_dataset_from_directory\nimport os\n\n# --- CONFIGURATION ---\nTRAIN_DIR = '/kaggle/input/pixel-play-26/Avenue_Corrupted-20251221T112159Z-3-001/Avenue_Corrupted/Dataset/training_videos'\nIMG_HEIGHT, IMG_WIDTH = 128, 128\nBATCH_SIZE = 32\n\n# 1. Load raw images\nraw_ds = image_dataset_from_directory(\n    TRAIN_DIR,\n    image_size=(IMG_HEIGHT, IMG_WIDTH),\n    batch_size=BATCH_SIZE,\n    label_mode=None, \n    shuffle=True\n)\n\n# 2. Preprocessing: Normalization and Autoencoder Pair (Input, Target)\ndef process_data(images):\n    # Normalize to [0, 1]\n    norm_imgs = tf.cast(images, tf.float32) / 255.0\n    # For an autoencoder, the input and the target are the same\n    return norm_imgs, norm_imgs\n\ntrain_generator = (\n    raw_ds\n    .map(process_data, num_parallel_calls=tf.data.AUTOTUNE)\n    .cache()\n    .prefetch(buffer_size=tf.data.AUTOTUNE)\n)\n\nprint(\"âœ… Preprocessing complete. Ready for high-capacity training!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T08:06:55.240084Z","iopub.execute_input":"2026-01-03T08:06:55.240650Z","iopub.status.idle":"2026-01-03T08:07:31.555932Z","shell.execute_reply.started":"2026-01-03T08:06:55.240621Z","shell.execute_reply":"2026-01-03T08:07:31.555125Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models, applications\n\ndef build_semantic_backbone():\n    # ResNet-101 (R101) for semantic feature extraction\n    base_model = applications.ResNet101(\n        input_shape=(128, 128, 3), \n        include_top=False, \n        weights='imagenet'\n    )\n    base_model.trainable = False \n\n    # GAP layer converts convolutional maps into high-level features\n    model = models.Sequential([\n        base_model,\n        layers.GlobalAveragePooling2D() \n    ])\n    return model\n\nfeature_extractor = build_semantic_backbone()\nprint(\"ðŸš€ Optimized Backbone Ready (ResNet-101)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T08:07:33.844153Z","iopub.execute_input":"2026-01-03T08:07:33.844778Z","iopub.status.idle":"2026-01-03T08:07:37.751991Z","shell.execute_reply.started":"2026-01-03T08:07:33.844752Z","shell.execute_reply":"2026-01-03T08:07:37.751314Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras import layers, models\n\ndef build_optimized_dae(input_dim=2048):\n    inputs = layers.Input(shape=(input_dim,))\n\n    # -------------------------------------------------\n    # Add noise to UNCORRUPTED data \n    # -------------------------------------------------\n    x = layers.GaussianNoise(0.1)(inputs)\n\n    # -------------------------------------------------\n    # Wide INPUT layer (NEW)\n    # -------------------------------------------------\n    x = layers.Dense(1536)(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('sigmoid')(x)\n\n    # -------------------------------------------------\n    # Encoder (UNCHANGED)\n    # -------------------------------------------------\n    x = layers.Dense(50)(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('sigmoid')(x)\n\n    # -------------------------------------------------\n    # Code layer (UNCHANGED)\n    # -------------------------------------------------\n    code = layers.Dense(30)(x)\n    code = layers.BatchNormalization()(code)\n    code = layers.Activation('sigmoid')(code)\n\n    # -------------------------------------------------\n    # Decoder (UNCHANGED)\n    # -------------------------------------------------\n    x = layers.Dense(50)(code)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('sigmoid')(x)\n\n    # -------------------------------------------------\n    # Wide OUTPUT layer (NEW)\n    # -------------------------------------------------\n    x = layers.Dense(1536)(x)\n    x = layers.BatchNormalization()(x)\n    #x = layers.Activation('sigmoid')(code) no sigmoid in output\n\n    # -------------------------------------------------\n    # Final reconstruction (UNCHANGED)\n    # -------------------------------------------------\n    outputs = layers.Dense(input_dim, activation='linear')(x)\n\n    model = models.Model(inputs, outputs)\n    model.compile(optimizer='adam', loss='mse')\n    return model\n\ndae_model = build_optimized_dae()\nprint(\"âœ… Optimized DAE with wide input/output built\")\ndae_model.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T08:07:44.263381Z","iopub.execute_input":"2026-01-03T08:07:44.264023Z","iopub.status.idle":"2026-01-03T08:07:44.339292Z","shell.execute_reply.started":"2026-01-03T08:07:44.263993Z","shell.execute_reply":"2026-01-03T08:07:44.338664Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\n# 1. Faster Training Data Loader\ntrain_ds = tf.keras.utils.image_dataset_from_directory(\n    TRAIN_DIR, image_size=(128, 128), batch_size=128, label_mode=None, shuffle=True\n)\n\n# 2. Optimized Extraction Phase (Maximum P100 throughput)\nprint(\"--- Phase 1: High-Speed Semantic Extraction ---\")\nall_train_features = []\nfor batch in train_ds:\n    batch_norm = tf.cast(batch, tf.float32) / 255.0\n    # Batch predict is faster than single predict \n    feats = feature_extractor.predict(batch_norm, verbose=0)\n    all_train_features.append(feats)\n\ntrain_vectors = np.vstack(all_train_features)\n\n# 3. DAE Training (Converges in seconds with semantic vectors) \nprint(f\"--- Phase 2: Training on {train_vectors.shape[1]}-dim semantic space ---\")\ndae_model.fit(\n    train_vectors, train_vectors, \n    epochs=150, batch_size=120, verbose=1 # Batch size 120 from paper \n)\n\ndae_model.save('paper_optimized_model.keras')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T08:07:49.428054Z","iopub.execute_input":"2026-01-03T08:07:49.428650Z","iopub.status.idle":"2026-01-03T08:09:12.615451Z","shell.execute_reply.started":"2026-01-03T08:07:49.428620Z","shell.execute_reply":"2026-01-03T08:09:12.614614Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import re, os\nimport pandas as pd\nfrom scipy.stats import rankdata\n# import pandas as pd\nimport numpy as np\nfrom scipy.ndimage import gaussian_filter1d\n\nTEST_PATH='/kaggle/input/pixel-play-26/Avenue_Corrupted-20251221T112159Z-3-001/Avenue_Corrupted/Dataset/testing_videos'\n# 1. Config Test Loader\ntest_ds = tf.keras.utils.image_dataset_from_directory(\n    TEST_PATH, image_size=(128, 128), batch_size=64, label_mode=None, shuffle=False\n)\ntest_filenames = test_ds.file_paths\n\n# 2. Batched Reconstruction Error Calculation \nall_errors = []\nprint(f\"--- Processing {len(test_filenames)} test frames in batches ---\")\n\nfor batch in test_ds:\n    batch_norm = tf.cast(batch, tf.float32) / 255.0\n    # Process 64 images at once\n    feats = feature_extractor.predict(batch_norm, verbose=0)\n    recons = dae_model.predict(feats, verbose=0)\n    \n    # Calculate MSE reconstruction error for the entire batch \n    batch_mse = np.mean((feats - recons)**2, axis=1)\n    all_errors.extend(batch_mse)\n\n# 3. Paper-Based ID Formatting (1_939)\ndef get_clean_id(p):\n    parts = p.split(os.sep)\n    f_num = int(re.findall(r'\\d+', parts[-2])[-1])\n    i_num = int(re.findall(r'\\d+', parts[-1])[-1])\n    return f\"{f_num}_{i_num}\"\n\n# 4. Save Final Submission\nsubmission_df = pd.DataFrame({\n    'Id': [get_clean_id(p) for p in test_filenames],\n    'Predicted': rankdata(all_errors) / len(all_errors)\n})\n\n\n\n# 1. Load your baseline\ndf = submission_df\ndf[['Video', 'Frame']] = df['Id'].str.split('_', expand=True).astype(int)\ndf = df.sort_values(['Video', 'Frame'])\n\n# 2. MSE -> PSNR Conversion\n# Peak Signal-to-Noise Ratio focuses on the reconstruction quality\nepsilon = 1e-10\ndf['PSNR'] = 10 * np.log10(1.0 / (df['Predicted'] + epsilon))\n\n# 3. Normalization Strategy\nSTRATEGY = 'GLOBAL' \n\nif STRATEGY == 'PER_VIDEO':\n    def norm_func(x):\n        return 1 - ((x - x.min()) / (x.max() - x.min() + epsilon))\n    df['Anomaly_Score'] = df.groupby('Video')['PSNR'].transform(norm_func)\nelse:\n    # Global normalization preserves the 'intensity' difference between videos\n    p_min, p_max = df['PSNR'].min(), df['PSNR'].max()\n    df['Anomaly_Score'] = 1 - ((df['PSNR'] - p_min) / (p_max - p_min + epsilon))\n\n# 4. Gaussian Smoothing (More precise than Moving Average)\ndf['Smoothed'] = df.groupby('Video')['Anomaly_Score'].transform(\n    lambda x: gaussian_filter1d(x, sigma=3)\n)\n\n# 5. Save the two best candidates\n# df[['Id', 'Anomaly_Score']].rename(columns={'Anomaly_Score': 'Predicted'}).to_csv('sub_psnr_only.csv', index=False)\ndf[['Id', 'Smoothed']].rename(columns={'Smoothed': 'Predicted'}).to_csv('sub_psnr_gaussian.csv', index=False)\n\nprint('sub_psnr_gaussian.csv')\n\n\n\n# submission_df.to_csv('submission_paper_semantic_optimized.csv', index=False)\n# print(\"ðŸš€ Optimized Submission Saved!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T07:56:52.964522Z","iopub.execute_input":"2026-01-03T07:56:52.964808Z","iopub.status.idle":"2026-01-03T07:57:49.296660Z","shell.execute_reply.started":"2026-01-03T07:56:52.964784Z","shell.execute_reply":"2026-01-03T07:57:49.295911Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import re, os\nimport pandas as pd\nfrom scipy.stats import rankdata\nTEST_PATH='/kaggle/input/pixel-play-26/Avenue_Corrupted-20251221T112159Z-3-001/Avenue_Corrupted/Dataset/testing_videos'\n# 1. Config Test Loader\ntest_ds = tf.keras.utils.image_dataset_from_directory(\n    TEST_PATH, image_size=(128, 128), batch_size=64, label_mode=None, shuffle=False\n)\ntest_filenames = test_ds.file_paths\n\n# 2. Batched Reconstruction Error Calculation [cite: 268, 271]\nall_errors = []\nprint(f\"--- Processing {len(test_filenames)} test frames in batches ---\")\n\nfor batch in test_ds:\n    batch_norm = tf.cast(batch, tf.float32) / 255.0\n    # Process 64 images at once\n    feats = feature_extractor.predict(batch_norm, verbose=0)\n    recons = dae_model.predict(feats, verbose=0)\n    \n    # Calculate MSE reconstruction error for the entire batch [cite: 268, 271]\n    batch_mse = np.mean((feats - recons)**2, axis=1)\n    all_errors.extend(batch_mse)\n\n# 3. Paper-Based ID Formatting (1_939)\ndef get_clean_id(p):\n    parts = p.split(os.sep)\n    f_num = int(re.findall(r'\\d+', parts[-2])[-1])\n    i_num = int(re.findall(r'\\d+', parts[-1])[-1])\n    return f\"{f_num}_{i_num}\"\n\n# 4. Save Final 0.85 Target Submission\nsubmission_df = pd.DataFrame({\n    'Id': [get_clean_id(p) for p in test_filenames],\n    'Predicted': rankdata(all_errors) / len(all_errors)\n})\n\nsubmission_df.to_csv('submission_paper_semantic_optimized.csv', index=False)\nprint(\"ðŸš€ Optimized Submission Saved!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T08:09:33.657506Z","iopub.execute_input":"2026-01-03T08:09:33.658108Z","iopub.status.idle":"2026-01-03T08:10:40.191022Z","shell.execute_reply.started":"2026-01-03T08:09:33.658077Z","shell.execute_reply":"2026-01-03T08:10:40.190360Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom scipy.ndimage import gaussian_filter1d\n\n# 1. Load your best baseline\ndf = pd.read_csv('/kaggle/working/submission_paper_semantic_optimized.csv')\ndf[['Video', 'Frame']] = df['Id'].str.split('_', expand=True).astype(int)\ndf = df.sort_values(['Video', 'Frame'])\n\n# 2. MSE -> PSNR Conversion\n# Peak Signal-to-Noise Ratio focuses on the reconstruction quality\nepsilon = 1e-10\ndf['PSNR'] = 10 * np.log10(1.0 / (df['Predicted'] + epsilon))\n\n# 3. Choose your Normalization Strategy\n# If Per-Video lowered your score before, try 'GLOBAL'\nSTRATEGY = 'GLOBAL' \n\nif STRATEGY == 'PER_VIDEO':\n    def norm_func(x):\n        return 1 - ((x - x.min()) / (x.max() - x.min() + epsilon))\n    df['Anomaly_Score'] = df.groupby('Video')['PSNR'].transform(norm_func)\nelse:\n    # Global normalization preserves the 'intensity' difference between videos\n    p_min, p_max = df['PSNR'].min(), df['PSNR'].max()\n    df['Anomaly_Score'] = 1 - ((df['PSNR'] - p_min) / (p_max - p_min + epsilon))\n\n# 4. Gaussian Smoothing (More precise than Moving Average)\n# sigma=1.0 or 1.5 is the 'sweet spot' for 24-30fps video\ndf['Smoothed'] = df.groupby('Video')['Anomaly_Score'].transform(\n    lambda x: gaussian_filter1d(x, sigma=1.2)\n)\n\n# 5. Save the two best candidates\ndf[['Id', 'Anomaly_Score']].rename(columns={'Anomaly_Score': 'Predicted'}).to_csv('sub_psnr_only.csv', index=False)\ndf[['Id', 'Smoothed']].rename(columns={'Smoothed': 'Predicted'}).to_csv('sub_psnr_gaussian.csv', index=False)\n\nprint(\"Generated 'sub_psnr_only.csv' and 'sub_psnr_gaussian.csv'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T08:11:33.408964Z","iopub.execute_input":"2026-01-03T08:11:33.409623Z","iopub.status.idle":"2026-01-03T08:11:33.504446Z","shell.execute_reply.started":"2026-01-03T08:11:33.409592Z","shell.execute_reply":"2026-01-03T08:11:33.503639Z"}},"outputs":[],"execution_count":null}]}